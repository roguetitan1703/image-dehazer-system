{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow===2.2.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow===2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow===2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class DehazeModel:\n",
    "    def __init__(self, model_path=None):\n",
    "        \"\"\"\n",
    "        Initializes the DehazeModel class, loading the model if a model path is provided.\n",
    "        \n",
    "        Args:\n",
    "        - model_path (str): Path to the saved model.\n",
    "        \"\"\"\n",
    "        if model_path:\n",
    "            self.load_model(model_path)\n",
    "        else:\n",
    "            self.model = None\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Loads the model architecture and weights.\n",
    "        \n",
    "        Args:\n",
    "        - model_path (str): Path to the saved model file.\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)  # Load the entire model\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Preprocesses an image from the specified path to prepare it for model input.\n",
    "        \n",
    "        Args:\n",
    "        - img_path (str): Path to the image file.\n",
    "        \n",
    "        Returns:\n",
    "        - img (tf.Tensor): Preprocessed image tensor ready for prediction.\n",
    "        \"\"\"\n",
    "        # Load and decode the image\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.io.decode_jpeg(img, channels=3)\n",
    "        \n",
    "        # Resize image to match the model's expected input size (224x224)\n",
    "        img = tf.image.resize(img, size=(224, 224), antialias=True)\n",
    "        img = img / 255.0  # Normalize to [0, 1] range\n",
    "        img = tf.expand_dims(img, axis=0)  # Expand dims for batch size of 1\n",
    "        return img\n",
    "        \n",
    "        # # Resize image based on its orientation\n",
    "        # if img.shape[1] > img.shape[0]:  # Landscape orientation\n",
    "        #     img = tf.image.resize(img, size=(1080, 1920), antialias=True)\n",
    "        # elif img.shape[1] < img.shape[0]:  # Portrait orientation\n",
    "        #     img = tf.image.resize(img, size=(1920, 1080), antialias=True)\n",
    "        \n",
    "        # img = img / 255.0  # Normalize to [0, 1] range\n",
    "        # img = tf.expand_dims(img, axis=0)  # Expand dims for batch size of 1\n",
    "        # return img\n",
    "\n",
    "    def predict(self, img):\n",
    "        \"\"\"\n",
    "        Predicts the dehazed image for the given preprocessed image tensor.\n",
    "        \n",
    "        Args:\n",
    "        - img (tf.Tensor): Preprocessed image tensor.\n",
    "        \n",
    "        Returns:\n",
    "        - tf.Tensor: Predicted dehazed image tensor.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded. Please load the model first.\")\n",
    "        return self.model(img, training=False)\n",
    "\n",
    "    def process_and_predict(self, img_path):\n",
    "        \"\"\"\n",
    "        Processes an image and predicts the dehazed output.\n",
    "        \n",
    "        Args:\n",
    "        - img_path (str): Path to the image file.\n",
    "        \n",
    "        Returns:\n",
    "        - tf.Tensor: Predicted dehazed image tensor.\n",
    "        \"\"\"\n",
    "        img = self.preprocess_image(img_path)\n",
    "        return self.predict(img)\n",
    "\n",
    "    def display_results(self, img_path, original_path):\n",
    "        \"\"\"\n",
    "        Displays the hazy and predicted dehazed images side by side.\n",
    "        \n",
    "        Args:\n",
    "        - img_path (str): Path to the hazy image.\n",
    "        \"\"\"\n",
    "        hazy_img = self.preprocess_image(img_path)\n",
    "        original_img = self.preprocess_image(original_path)\n",
    "        dehazed_img = self.predict(hazy_img)\n",
    "\n",
    "        # Display both the original hazy and dehazed images\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        display_list = [hazy_img[0], dehazed_img[0], original_img[0]]\n",
    "        title = ['Hazy Image', 'Dehazed Image','Original Image',]\n",
    "\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.title(title[i], fontsize=15)\n",
    "            plt.imshow(display_list[i])\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "class RealTimeDehazer:\n",
    "    def __init__(self, model_path, capture_interval=3, capture_index=0):\n",
    "        \"\"\"\n",
    "        Initializes the RealTimeDehazer with the model and sets up camera.\n",
    "\n",
    "        Args:\n",
    "        - model_path (str): Path to the dehaze model.\n",
    "        - capture_interval (int): Time in seconds between each dehazed frame capture.\n",
    "        \"\"\"\n",
    "        # Load the dehazing model\n",
    "        self.dehaze_model = DehazeModel(model_path)\n",
    "        self.capture_interval = capture_interval  # Interval to capture image for dehazing\n",
    "        self.last_capture_time = time.time()\n",
    "        \n",
    "        # Initialize the camera\n",
    "        self.cap = cv2.VideoCapture(capture_index)  # Use 0 for default camera, or specify the external camera ID\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(\"Could not open video device\")\n",
    "        \n",
    "        # Start a thread for real-time dehazing\n",
    "        # self.hazify = self.add_haze\n",
    "        # self.hazify = self.add_complex_haze\n",
    "        self.hazify = self.add_uneven_haze\n",
    "        self.haze_intensity = 0.4\n",
    "        self.dehazed_image = None\n",
    "        self.running = True\n",
    "        self.dehaze_thread = Thread(target=self._dehaze_loop)\n",
    "        self.dehaze_thread.start()\n",
    "        \n",
    "\n",
    "    def _dehaze_loop(self):\n",
    "        \"\"\"\n",
    "        Continuously captures and dehazes images at the specified interval.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            current_time = time.time()\n",
    "            # Capture and dehaze image every `capture_interval` seconds\n",
    "            if current_time - self.last_capture_time >= self.capture_interval:\n",
    "                ret, frame = self.cap.read()\n",
    "                if ret:\n",
    "                    # Preprocess and dehaze the captured frame\n",
    "                    hazed_frame = self.hazify(frame, self.haze_intensity)\n",
    "                    img_tensor = self.dehaze_model.preprocess_image_from_array(hazed_frame)\n",
    "                    self.dehazed_image = self.dehaze_model.predict(img_tensor)[0].numpy()\n",
    "                    self.last_capture_time = current_time\n",
    "    \n",
    "    # Preprocessing modification in DehazeModel to handle images from arrays\n",
    "    def preprocess_image_from_array(self, img_array):\n",
    "        \"\"\"\n",
    "        Preprocesses an image from an array for prediction.\n",
    "\n",
    "        Args:\n",
    "        - img_array (np.array): Image array captured from camera.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: Preprocessed image tensor.\n",
    "        \"\"\"\n",
    "        img = tf.image.resize(img_array, (224, 224))\n",
    "        img = tf.convert_to_tensor(img, dtype=tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "        img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "        return img\n",
    "\n",
    "    def add_haze(self,image, haze_intensity=0.5):\n",
    "        \"\"\"\n",
    "        Adds haze to an image.\n",
    "\n",
    "        Args:\n",
    "        - image (np.array): Original image.\n",
    "        - haze_intensity (float): Intensity of the haze effect (0.0 to 1.0).\n",
    "\n",
    "        Returns:\n",
    "        - np.array: Hazy image.\n",
    "        \"\"\"\n",
    "        # Create a solid haze layer (white color with some intensity)\n",
    "        haze_layer = np.ones_like(image, dtype=np.float32) * 255  # White haze\n",
    "        haze_layer = haze_layer.astype(np.uint8)\n",
    "\n",
    "        # Blend the original image and the haze layer\n",
    "        hazy_image = cv2.addWeighted(image, 1 - haze_intensity, haze_layer, haze_intensity, 0)\n",
    "        return hazy_image\n",
    "    \n",
    "    def add_complex_haze(self, image, haze_intensity=0.5):\n",
    "        \"\"\"\n",
    "        Adds a more complex haze to an image using random pixel values.\n",
    "\n",
    "        Args:\n",
    "        - image (np.array): Original image.\n",
    "        - haze_intensity (float): Intensity of the haze effect (0.0 to 1.0).\n",
    "\n",
    "        Returns:\n",
    "        - np.array: Hazy image.\n",
    "        \"\"\"\n",
    "        # Generate random haze layer\n",
    "        haze_layer = np.random.randint(200, 255, size=image.shape, dtype=np.uint8)  # Random haze values\n",
    "\n",
    "        # Blend the original image and the random haze layer\n",
    "        hazy_image = cv2.addWeighted(image, 1 - haze_intensity, haze_layer, haze_intensity, 0)\n",
    "        return hazy_image\n",
    "    \n",
    "    def add_uneven_haze(self, image, haze_intensity=0.8):\n",
    "        \"\"\"\n",
    "        Adds uneven haze to an image based on a randomly generated mask.\n",
    "\n",
    "        Args:\n",
    "        - image (np.array): Original image.\n",
    "        - haze_intensity (float): Intensity of the haze effect (0.0 to 1.0).\n",
    "\n",
    "        Returns:\n",
    "        - np.array: Hazy image.\n",
    "        \"\"\"\n",
    "        # Generate random haze layer\n",
    "        haze_layer = np.random.randint(200, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "        # Create a mask for uneven haze (random noise)\n",
    "        noise_mask = np.random.rand(*image.shape[:2])  # Random values between 0 and 1\n",
    "        noise_mask = (noise_mask * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "\n",
    "        # Apply a Gaussian blur to the noise mask for smoother transitions\n",
    "        noise_mask = cv2.GaussianBlur(noise_mask, (21, 21), 0)\n",
    "\n",
    "        # Normalize the mask to have values between 0 and 1\n",
    "        normalized_mask = noise_mask.astype(np.float32) / 255.0\n",
    "\n",
    "        # Compute beta as a single value (optional adjustment)\n",
    "        beta = haze_intensity * np.mean(normalized_mask)  # Average to create a single float value for blending\n",
    "\n",
    "        # Blend the original image and the haze layer unevenly based on the mask\n",
    "        hazy_image = cv2.addWeighted(image, 1 - haze_intensity, haze_layer, beta, 0)\n",
    "        return hazy_image\n",
    "\n",
    "    def show_feed(self):\n",
    "        \"\"\"\n",
    "        Displays the live camera feed and the dehazed image side by side.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            # Resize frame if needed\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "            # hazy_frame = self.dehaze_model.preprocess_image_from_array(hazy_frame)\n",
    "            # Add haze to the original frame\n",
    "            # hazy_frame = self.add_haze(frame, haze_intensity=0.5)\n",
    "            hazy_frame = self.hazify(frame, self.haze_intensity)\n",
    "\n",
    "            # Prepare dehazed image for display\n",
    "            if self.dehazed_image is not None:\n",
    "                dehazed_display = (self.dehazed_image * 255).astype(np.uint8)\n",
    "                dehazed_display = cv2.resize(dehazed_display, (640, 480))\n",
    "            else:\n",
    "                dehazed_display = np.zeros_like(frame)\n",
    "\n",
    "            # Concatenate the hazy feed and dehazed images side by side\n",
    "            combined_display = np.concatenate((hazy_frame, dehazed_display), axis=1)\n",
    "            cv2.imshow(\"Camera Feed and Dehazed Image\", combined_display)\n",
    "\n",
    "            # Exit the display loop on pressing 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "                self.stop()\n",
    "                break\n",
    "\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stops the real-time dehazing and releases the camera.\n",
    "        \"\"\"\n",
    "        self.running = False\n",
    "        self.dehaze_thread.join()\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DehazeModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Create RealTimeDehazer instance and start real-time dehazing\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m realtime_dehazer \u001b[38;5;241m=\u001b[39m \u001b[43mRealTimeDehazer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgman_net_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mRealTimeDehazer.__init__\u001b[1;34m(self, model_path, capture_interval, capture_index)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mInitializes the RealTimeDehazer with the model and sets up camera.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m- capture_interval (int): Time in seconds between each dehazed frame capture.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load the dehazing model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdehaze_model \u001b[38;5;241m=\u001b[39m \u001b[43mDehazeModel\u001b[49m(model_path)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture_interval \u001b[38;5;241m=\u001b[39m capture_interval  \u001b[38;5;66;03m# Interval to capture image for dehazing\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_capture_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DehazeModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage:\n",
    "# Create RealTimeDehazer instance and start real-time dehazing\n",
    "realtime_dehazer = RealTimeDehazer(model_path='gman_net_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'realtime_dehazer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrealtime_dehazer\u001b[49m\u001b[38;5;241m.\u001b[39mshow_feed()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'realtime_dehazer' is not defined"
     ]
    }
   ],
   "source": [
    "realtime_dehazer.show_feed()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to calculate PSNR\n",
    "def calculate_psnr(gt_image, pred_image):\n",
    "    mse = np.mean((gt_image - pred_image) ** 2)\n",
    "    if mse == 0:  # Avoid division by zero\n",
    "        return float('inf')\n",
    "    max_pixel = 255.0  # Assuming 8-bit image depth\n",
    "    psnr = 10 * np.log10((max_pixel ** 2) / mse)\n",
    "    return psnr\n",
    "\n",
    "# Function to calculate SSIM\n",
    "def calculate_ssim(gt_image, pred_image):\n",
    "    ssim_value, _ = ssim(gt_image, pred_image, full=True, multichannel=True)\n",
    "    return ssim_value\n",
    "\n",
    "# Function to calculate MSE\n",
    "def calculate_mse(gt_image, pred_image):\n",
    "    mse = np.mean((gt_image - pred_image) ** 2)\n",
    "    return mse\n",
    "\n",
    "# Function to calculate Absolute Difference (AD)\n",
    "def calculate_ad(gt_image, pred_image):\n",
    "    ad = np.mean(np.abs(gt_image - pred_image))\n",
    "    return ad\n",
    "\n",
    "# Evaluation function for the model\n",
    "def evaluate_dehaze_model(gt_images, pred_images):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    mse_values = []\n",
    "    ad_values = []\n",
    "    \n",
    "    for gt_image, pred_image in zip(gt_images, pred_images):\n",
    "        psnr_values.append(calculate_psnr(gt_image, pred_image))\n",
    "        ssim_values.append(calculate_ssim(gt_image, pred_image))\n",
    "        mse_values.append(calculate_mse(gt_image, pred_image))\n",
    "        ad_values.append(calculate_ad(gt_image, pred_image))\n",
    "    \n",
    "    # Print the average results\n",
    "    print(\"Average PSNR:\", np.mean(psnr_values))\n",
    "    print(\"Average SSIM:\", np.mean(ssim_values))\n",
    "    print(\"Average MSE:\", np.mean(mse_values))\n",
    "    print(\"Average AD:\", np.mean(ad_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming you have lists `gt_images` and `pred_images` with image arrays\n",
    "# You can read the images using cv2.imread or any other image loader\n",
    "# e.g., gt_images = [cv2.imread(\"gt1.png\"), cv2.imread(\"gt2.png\"), ...]\n",
    "#       pred_images = [cv2.imread(\"pred1.png\"), cv2.imread(\"pred2.png\"), ...]\n",
    "\n",
    "# evaluate_dehaze_model(gt_images, pred_images)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
